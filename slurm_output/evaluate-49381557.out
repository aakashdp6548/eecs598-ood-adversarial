03/18/2023 11:41:20 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False
/home/aakashdp/eecs598/eecs598-ood-adversarial/env/lib/python3.10/site-packages/transformers/data/processors/glue.py:475: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py
  warnings.warn(DEPRECATION_WARNING.format("processor"), FutureWarning)
Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.bias', 'vocab_transform.weight', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias']
- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.bias', 'classifier.bias', 'classifier.weight', 'pre_classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
03/18/2023 11:41:22 - INFO - __main__ -   Training/evaluation parameters Namespace(data_dir='glue_data/QNLI/processed', model_type='distilbert', model_name_or_path='distilbert-base-uncased', task_name='qnli', output_dir='checkpoints/first_test', config_name='', tokenizer_name='', cache_dir='', max_seq_length=512, do_train=False, do_eval=True, evaluate_during_training=False, do_lower_case=True, per_gpu_train_batch_size=8, per_gpu_eval_batch_size=8, gradient_accumulation_steps=1, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=3.0, max_steps=-1, warmup_steps=0, logging_steps=50, save_steps=50, eval_all_checkpoints=False, no_cuda=False, overwrite_output_dir=False, overwrite_cache=False, seed=42, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', adv_lr=0, adv_steps=1, adv_init_mag=0, norm_type='l2', adv_max_norm=0, gpu='0', expname='default', comet=False, comet_key='', hidden_dropout_prob=0.1, attention_probs_dropout_prob=0, n_gpu=1, device=device(type='cuda'), output_mode='classification')
03/18/2023 11:41:23 - INFO - __main__ -   Evaluate the following checkpoints: ['checkpoints/first_test']
03/18/2023 11:41:23 - INFO - __main__ -   Loading features from cached file glue_data/QNLI/processed/cached_dev_distilbert-base-uncased_512_qnli
03/18/2023 11:41:24 - INFO - __main__ -   ***** Running evaluation first_test *****
03/18/2023 11:41:24 - INFO - __main__ -     Num examples = 5462
03/18/2023 11:41:24 - INFO - __main__ -     Batch size = 8
Evaluating:   0%|          | 0/683 [00:00<?, ?it/s]Evaluating:   0%|          | 1/683 [00:00<04:56,  2.30it/s]Evaluating:   2%|â–         | 13/683 [00:00<00:21, 30.91it/s]Evaluating:   4%|â–         | 27/683 [00:00<00:11, 58.46it/s]Evaluating:   6%|â–Œ         | 41/683 [00:00<00:08, 79.87it/s]Evaluating:   8%|â–Š         | 54/683 [00:00<00:06, 92.88it/s]Evaluating:  10%|â–‰         | 66/683 [00:00<00:06, 99.78it/s]Evaluating:  12%|â–ˆâ–        | 80/683 [00:01<00:05, 110.44it/s]Evaluating:  14%|â–ˆâ–        | 94/683 [00:01<00:05, 116.38it/s]Evaluating:  16%|â–ˆâ–Œ        | 107/683 [00:01<00:04, 119.13it/s]Evaluating:  18%|â–ˆâ–Š        | 121/683 [00:01<00:04, 122.31it/s]Evaluating:  20%|â–ˆâ–‰        | 135/683 [00:01<00:04, 126.67it/s]Evaluating:  22%|â–ˆâ–ˆâ–       | 149/683 [00:01<00:04, 126.01it/s]Evaluating:  24%|â–ˆâ–ˆâ–       | 163/683 [00:01<00:04, 129.11it/s]Evaluating:  26%|â–ˆâ–ˆâ–Œ       | 177/683 [00:01<00:03, 127.71it/s]Evaluating:  28%|â–ˆâ–ˆâ–Š       | 192/683 [00:01<00:03, 132.20it/s]Evaluating:  30%|â–ˆâ–ˆâ–ˆ       | 206/683 [00:02<00:03, 132.66it/s]Evaluating:  32%|â–ˆâ–ˆâ–ˆâ–      | 220/683 [00:02<00:03, 133.73it/s]Evaluating:  34%|â–ˆâ–ˆâ–ˆâ–      | 234/683 [00:02<00:03, 131.49it/s]Evaluating:  36%|â–ˆâ–ˆâ–ˆâ–‹      | 248/683 [00:02<00:03, 130.69it/s]Evaluating:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 262/683 [00:02<00:03, 131.97it/s]Evaluating:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 276/683 [00:02<00:03, 131.59it/s]Evaluating:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 290/683 [00:02<00:02, 131.57it/s]Evaluating:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 304/683 [00:02<00:02, 130.63it/s]Evaluating:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 318/683 [00:02<00:02, 125.96it/s]Evaluating:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 331/683 [00:02<00:02, 125.98it/s]Evaluating:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 346/683 [00:03<00:02, 132.26it/s]Evaluating:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 360/683 [00:03<00:02, 132.21it/s]Evaluating:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 374/683 [00:03<00:02, 131.89it/s]Evaluating:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 388/683 [00:03<00:02, 132.52it/s]Evaluating:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 402/683 [00:03<00:02, 130.05it/s]Evaluating:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 416/683 [00:03<00:02, 130.26it/s]Evaluating:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 430/683 [00:03<00:01, 129.35it/s]Evaluating:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 444/683 [00:03<00:01, 129.35it/s]Evaluating:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 459/683 [00:03<00:01, 132.51it/s]Evaluating:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 473/683 [00:04<00:01, 132.70it/s]Evaluating:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 487/683 [00:04<00:01, 134.65it/s]Evaluating:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 501/683 [00:04<00:01, 134.85it/s]Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 515/683 [00:04<00:01, 134.72it/s]Evaluating:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 529/683 [00:04<00:01, 135.38it/s]Evaluating:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 543/683 [00:04<00:01, 135.67it/s]Evaluating:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 557/683 [00:04<00:00, 136.49it/s]Evaluating:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 571/683 [00:04<00:00, 135.39it/s]Evaluating:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 585/683 [00:04<00:00, 134.22it/s]Evaluating:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 599/683 [00:04<00:00, 135.56it/s]Evaluating:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 613/683 [00:05<00:00, 132.31it/s]Evaluating:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 627/683 [00:05<00:00, 134.41it/s]Evaluating:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 642/683 [00:05<00:00, 136.56it/s]Evaluating:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 656/683 [00:05<00:00, 134.77it/s]Evaluating:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 670/683 [00:05<00:00, 134.37it/s]Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 683/683 [00:05<00:00, 121.97it/s]
/home/aakashdp/eecs598/eecs598-ood-adversarial/env/lib/python3.10/site-packages/transformers/data/metrics/__init__.py:61: FutureWarning: This metric will be removed from the library soon, metrics should be handled with the ðŸ¤— Evaluate library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py
  warnings.warn(DEPRECATION_WARNING, FutureWarning)
/home/aakashdp/eecs598/eecs598-ood-adversarial/env/lib/python3.10/site-packages/transformers/data/metrics/__init__.py:31: FutureWarning: This metric will be removed from the library soon, metrics should be handled with the ðŸ¤— Evaluate library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py
  warnings.warn(DEPRECATION_WARNING, FutureWarning)
03/18/2023 11:41:32 - INFO - __main__ -   ***** Eval results first_test *****
03/18/2023 11:41:32 - INFO - __main__ -     acc = 0.8903332112779202
Finished evaluation
