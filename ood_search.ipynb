{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "347c6b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DistilBertConfig, DistilBertForSequenceClassification, DistilBertTokenizer\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from transformers import glue_convert_examples_to_features\n",
    "from transformers import glue_processors\n",
    "from typing import List, Optional, Union\n",
    "from dataclasses import dataclass\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c640679",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_path = './checkpoints/mnli_baseline_distilbert-2023-04-07_10-48-14/checkpoint-last'\n",
    "config = DistilBertConfig.from_pretrained(\n",
    "    classifier_path,\n",
    "    num_labels=3,\n",
    "    finetuning_task='mnli',\n",
    "    attention_probs_dropout_prob=0,\n",
    "    hidden_dropout_prob=0.1\n",
    ")\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(\n",
    "    classifier_path,\n",
    "    do_lower_case=True,\n",
    ")\n",
    "model = DistilBertForSequenceClassification.from_pretrained(\n",
    "    classifier_path,\n",
    "    config=config,\n",
    "    ignore_mismatched_sizes=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e28f7500",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class InputExample:\n",
    "    guid: str\n",
    "    text_a: str\n",
    "    text_b: str\n",
    "    label: Optional[str] = None\n",
    "        \n",
    "@dataclass(frozen=True)\n",
    "class InputFeatures:\n",
    "    input_ids: List[int]\n",
    "    attention_mask: Optional[List[int]] = None\n",
    "    token_type_ids: Optional[List[int]] = None\n",
    "    label: Optional[Union[int, float]] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "30b1dbed",
   "metadata": {},
   "outputs": [],
   "source": [
    "premise = \"i'm not sure what the overnight low was\"\n",
    "orig_hypothesis = \"I don't know how cold it got last night.\"\n",
    "orig_label = \"entailment\"\n",
    "hypotheses = [\n",
    "    \"They didn't see how long it got last day.\",\n",
    "    \"I don't know how cold it went last night.\",\n",
    "    \"I don't know how it had gone last night.\",\n",
    "    \"I don't know how it stayed the last night.\",\n",
    "    \"I knew how so it was a last night.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "534fc609",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(premise, hypotheses, tokenizer):\n",
    "    processor = glue_processors['mnli']()\n",
    "    label_list = [\"contradiction\", \"entailment\", \"neutral\"]\n",
    "    examples = []\n",
    "    for i, hypothesis in enumerate(hypotheses):\n",
    "        examples.append(InputExample(guid=f'test-{i}', text_a=premise, text_b=hypothesis, label='contradiction'))\n",
    "    \n",
    "    label_map = {label: i for i, label in enumerate(label_list)}\n",
    "    labels = [label_map[example.label] for example in examples]\n",
    "\n",
    "    batch_encoding = tokenizer(\n",
    "        [(example.text_a, example.text_b) for example in examples],\n",
    "        max_length=128,\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        return_token_type_ids=True\n",
    "    )\n",
    "\n",
    "    features = []\n",
    "    for i in range(len(examples)):\n",
    "        inputs = {k: batch_encoding[k][i] for k in batch_encoding}\n",
    "        feature = InputFeatures(**inputs, label=labels[i])\n",
    "        features.append(feature)\n",
    "\n",
    "    # Convert to Tensors and build dataset\n",
    "    all_input_ids = torch.tensor([f.input_ids for f in features], dtype=torch.long)\n",
    "    all_attention_mask = torch.tensor([f.attention_mask for f in features], dtype=torch.long)\n",
    "    all_token_type_ids = torch.tensor([f.token_type_ids for f in features], dtype=torch.long)\n",
    "    all_labels = torch.tensor([f.label for f in features], dtype=torch.long)\n",
    "\n",
    "    # dataset = TensorDataset(all_input_ids, all_attention_mask, all_token_type_ids, all_labels)\n",
    "    dataset = TensorDataset(all_input_ids, all_attention_mask, all_token_type_ids, all_labels)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "70e9a2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_data(premise, hypotheses, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "25e648c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 1, 1, 1, 0]\n"
     ]
    }
   ],
   "source": [
    "eval_dataloader = DataLoader(dataset, batch_size=16)\n",
    "for batch in eval_dataloader:\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        inputs = {\"input_ids\": batch[0], \"attention_mask\": batch[1], \"labels\": batch[3]}\n",
    "    _, logits = model(**inputs)[:2]\n",
    "    preds = logits.detach().cpu().numpy()\n",
    "    preds = np.argmax(preds, axis=1)\n",
    "\n",
    "    print(preds.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e9baea46",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_list = [\"contradiction\", \"entailment\", \"neutral\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "13aa5ae3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Premise: i'm not sure what the overnight low was\n",
      "Original hypothesis: I don't know how cold it got last night.\n",
      "Label: entailment\n",
      "--------------------\n",
      "They didn't see how long it got last day. --> neutral\n",
      "I don't know how cold it went last night. --> entailment\n",
      "I don't know how it had gone last night. --> entailment\n",
      "I don't know how it stayed the last night. --> entailment\n",
      "I knew how so it was a last night. --> contradiction\n"
     ]
    }
   ],
   "source": [
    "print(f'Premise: {premise}')\n",
    "print(f'Original hypothesis: {orig_hypothesis}')\n",
    "print(f'Label: {orig_label}')\n",
    "print('--------------------')\n",
    "for sentence, pred in zip(hypotheses, preds):\n",
    "    print(f'{sentence} --> {label_list[pred]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "428fb720",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
